import sys
import time
import logging
import numpy as np
import random
import os
import torch
from sklearn.metrics.pairwise import cosine_similarity
from .cover_tree import CoverTree
import math

def set_logger(name, timestamp):
    formatter=logging.Formatter('%(asctime)s %(levelname)s %(message)s')
    logger=logging.getLogger(f'{name}-Logger')
    file_handler=logging.FileHandler(f'./log-{name}-{timestamp}.log')
    file_handler.setFormatter(formatter)
    logger.addHandler(file_handler)
    console_handler=logging.StreamHandler(sys.stdout)
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)
    logger.setLevel(logging.INFO)
    return logger

def set_seed(seed):
    random.seed(seed) 
    np.random.seed(seed) 
    torch.manual_seed(seed) 
    if torch.cuda.is_available(): 
        torch.cuda.manual_seed_all(seed) 

def gen_data(trainloader, testloader, m):
    """
    This function generate data with new labels.
    New labels are generated by adding a new number which selected uniformly at random from [number].
    """
    sim = gen_sim(m)
    examples = enumerate(trainloader)

    train_data = []
    train_original = []
    while True:
        try:
            batch_idx, (example_data, example_targets) = next(examples)
            train_original.append(example_targets)
            train_data.append(example_data.squeeze(0).numpy())
        except:
            break
    train_dataset = list(zip(train_data, train_original))
    random.shuffle(train_dataset)
    train_data, train_original = zip(*train_dataset)
    train_data = np.array(train_data)
    train_original = np.array(train_original)
    train_label = np.copy(train_original)
    
    # sampling
    c, o = m.shape
    for i in range(o):
        p = np.nonzero(m[:,i])
        position = np.where(train_original==i)
        length = np.sum(train_original==i)
        t = 0
        for j in range(p[0].shape[0]):
            index = position[0][math.ceil(t*length):math.ceil((t+m[p[0][j],i])*length)]
            train_label[index] = p[0][j]
            t += m[p[0][j],i]

    instances = enumerate(testloader)

    test_data = []
    test_original = []
    while True:
        try:
            batch_index, (instances_data, instances_targets) = next(instances)
            test_original.append(instances_targets)
            test_data.append(instances_data.squeeze(0).numpy())
        except:
            break
    test_data = np.array(test_data)
    test_original = np.array(test_original)
    test_label = np.copy(test_original)
    
    for i in range(o):
        p = np.nonzero(m[:,i])
        position = np.where(test_original==i)
        length = np.sum(test_original==i)
        t = 0
        for j in range(p[0].shape[0]):
            index = position[0][math.ceil(t*length):math.ceil((t+m[p[0][j],i])*length)]
            test_label[index] = p[0][j]
            t += m[p[0][j],i]

    return train_data, train_label, train_original, test_data, test_label, test_original, sim


def gen_matrix(o, c, k):
    """
    o is number of original classes
    c is number of new classes
    k is number of mixings
    output a sampling matrix m
    """
    m = np.zeros((c, o))
    p = np.full((1,k), 1)
    for i in range(0, c, o):
        for col in range(o):
            for j in range(k):
                row = (col + j) % c
                if i+row < c:
                    m[i+row,col] = p[0][j]
    for i in range(o):
        num = np.count_nonzero(m[:,i])
        m[:,i] = m[:,i]/num
    return m

def gen_sim(m):
    """
    This function generate similarity matrix.
    Every row of input matrix m represent every new label.
    """

    b, a = m.shape
    new = []
    for i in range(b):
        new.append(m[i,:])
    cosine_dist = cosine_similarity(new)
    sim_matrix = torch.from_numpy(cosine_dist)

    return sim_matrix

def get_labels(label):
  
  label2index = dict()
  index2label = dict()
  for idx, element in enumerate(label):
    label2index[element] = idx
    index2label[idx] = element

  return label2index, index2label

def _print(self):
    def print_node(node, indent):
        if isinstance(node, CoverTree._LeafNode):
            print ("-" * indent, node)
        else:
            print ("-" * indent, node)
            for child in node.children:
                print_node(child, indent + 1)
    print_node(self.root, 0)

def path(self):

    pathes = []
    path_tmp = []

    def _path(node, path_tmp):
        
        if isinstance(node, CoverTree._LeafNode):
            path_tmp.append(node.ctr_idx) # all leaf node add a ctr_idx
            for number in node.idx:
                path_tmp.append(number)
                pathes.append(list(path_tmp))
                path_tmp.pop()
            path_tmp.pop() # all leaf add a ctr_idx
        else:
            path_tmp.append(node.ctr_idx)
            for child in node.children:
                _path(child, path_tmp)
            path_tmp.pop()

    _path(self.root, path_tmp)

    return pathes

def norm(x):
    m = np.max(x)
    n = np.min(x)
    x = (x-n) / (m-n)
    return x
