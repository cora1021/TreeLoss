\documentclass[10pt]{article}

\usepackage[margin=1in]{geometry}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage{bm}
\usepackage{natbib}
\usepackage[inline]{enumitem}
\usepackage{tikz}
\usepackage{booktabs}
\usepackage{subfigure}

\usepackage{color}
\usepackage{colortbl}
\definecolor{deepblue}{rgb}{0,0,0.5}
\definecolor{deepred}{rgb}{0.6,0,0}
\definecolor{deepgreen}{rgb}{0,0.5,0}
\definecolor{gray}{rgb}{0.7,0.7,0.7}

\usepackage{hyperref}
\hypersetup{
  colorlinks   = true, %Colours links instead of ugly boxes
  urlcolor     = black, %Colour for external hyperlinks
  linkcolor    = blue, %Colour of internal links
  citecolor    = blue  %Colour of citations
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\theoremstyle{definition}
\newtheorem{problem}{Problem}
\newtheorem{defn}{Definition}
\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\newtheorem{fact}{Fact}

\newcommand{\R}{\mathbb R}
\DeclareMathOperator{\vcdim}{VCdim}
\DeclareMathOperator{\ddim}{c_{\text{dd}}}
\DeclareMathOperator{\E}{\mathbb E}
\DeclareMathOperator{\nnz}{nnz}
\DeclareMathOperator{\determinant}{det}
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\softmax}{softmax}

\newcommand{\I}{\mathbf I}
\newcommand{\Q}{\mathbf Q}
\newcommand{\p}{\mathbf P}
\newcommand{\pb}{\bar {\p}}
\newcommand{\pbb}{\bar {\pb}}
\newcommand{\pr}{\bm \pi}
\newcommand{\epsapp}{\epsilon_{\text{app}}}
\newcommand{\epsest}{\epsilon_{\text{est}}}

\newcommand{\trans}[1]{{#1}^{T}}
\newcommand{\loss}{\ell}
\newcommand{\Loss}{\mathcal{L}}
\newcommand{\aaa}{\mathbf a}
\newcommand{\vv}{\mathbf v}
\newcommand{\uu}{\mathbf u}
\newcommand{\w}{\mathbf w}
\newcommand{\x}{\mathbf x}
\newcommand{\y}{\mathbf y}
\newcommand{\lone}[1]{{\lVert {#1} \rVert}_1}
\newcommand{\ltwo}[1]{{\lVert {#1} \rVert}_2}
\newcommand{\lp}[1]{{\lVert {#1} \rVert}_p}
\newcommand{\linf}[1]{{\lVert {#1} \rVert}_\infty}
\newcommand{\lF}[1]{{\lVert {#1} \rVert}_F}

\newcommand{\dist}[2]{d_{{#1},{#2}}}
\newcommand{\level}[1]{\texttt{level}({#1})}

\newcommand{\h}{\mathcal H}
\newcommand{\D}{\mathcal D}
\DeclareMathOperator*{\erm}{ERM}

\newcommand{\fixme}[1]{\noindent{\color{red}\textbf{FIXME:}  {#1}}}
\newcommand{\fixmemike}[1]{\noindent{\color{blue}\textbf{FIXME (Mike):}  {#1}}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}


\begin{center}
\Huge
Tree Regularization
\end{center}

\section{Introduction}

This note introduces \emph{tree regularization}.
For multi-class learning problems, tree regularization achieves a generalization error of $O(\sqrt{\log k / m})$ which is comparable to the tree loss's error of $O(\sqrt{1/m})$.
Tree regularization has several advantages over the tree loss, however:
\begin{enumerate}
    \item
        It can work with any loss function.
        For example, we can apply tree regularization to multiple regression, multi-label prediction, and objection detection problems.
    \item
        The optimal tree structure can be learned at training time and the problem remains convex.
    \item
        The analysis works for all optimization algorithms, not just stochastic gradient descent.
\end{enumerate}

\section{Notation}
Many regularized learning problems take the form
\begin{equation}
    \argmin_{W} \Loss(Z ; W) + \lambda R(W)^2
\end{equation}
where
$Z = \{z_1, ..., z_m\}$ is the training set,
$W$ is the model parameters,
\begin{equation}
    \Loss(Z ; W) = \frac 1m \sum_{i=1}^m \loss(z_i; W)
\end{equation}
and $R : W \to \R^+$ is a regularization function.

We assume that the parameters $W$ are given in matrix as a $k \times d$ matrix.
In the multi-class prediction problem,
each row $i$ is a $d$ dimensional vector that represents the parameter matrix for class $i$.

\section{Tree Regularization}

The Tree Regularizer is defined to be
\begin{equation}
    R(W, V, A) 
    = \sum_{i} \left\lVert \w_i - \sum_{j}A_{i,j} \vv_j \right\lVert
    = \sum_{i} \left\lVert \w_i - A_i V \right\lVert
\end{equation}

The idea of the convergence proof is to show that any loss function that is $\rho$-Lipschitz with respect to the L2 norm is $\rho/k$ Lipschitz with respect to the tree regularizer (for fixed $V$,$A$ and near the optimal solution).
Then applying the exercise at the end of the chapter solves the problem.

\end{document}
